# Smart Dustbin with Object Detection & Voice Recognition

**Overview**

- **Purpose:** Detect waste types (paper, plastic, etc.) from camera images and control a smart dustbin (open lid, count items, announce status).
- **Main scripts:** `smart_dustbin_smooth.py` (main app), `webcam_fresh.py` (demo), `train_roboflow.py` + `data_roboflow.yaml` (training).

**Quick Start**

- Install dependencies:

```powershell
cd "E:\minor project\try 1"
python -m pip install -r requirements.txt
```

- Run the main application:

```powershell
python smart_dustbin_smooth.py
```

- Run the webcam demo:

```powershell
python webcam_fresh.py
```

**How It Works (Simple)**

- **1. Capture:** Camera takes an image (frame).
- **2. Detect:** The model finds objects and returns rectangles (bounding boxes) with labels and confidence scores.
- **3. Filter:** The app removes overlapping/duplicate boxes (Non-Maximum Suppression).
- **4. Decide:** If confidence is high enough, the app maps the detected class to an action (e.g., open lid for plastic).
- **5. Act & Report:** The bin performs the action and can log or speak the result.

**Key Concepts (Plain English)**

- **Confidence:** How sure the model is (0â€“1). We ignore low-confidence detections (example: < 0.25).
- **Bounding box:** Rectangle around a detected object.
- **NMS (Non-Maximum Suppression):** Keeps the best rectangle when many overlap the same object.
- **mAP:** Score used during training to measure detection quality.

**Simple Rules Used by the App**

- **Confidence threshold:** Ignore detections below ~0.25.
- **Temporal smoothing:** Require the same detection in 2â€“3 consecutive frames before acting (reduces false triggers).
- **Priority rule:** If multiple valid classes appear, choose the highest-confidence one or use a defined priority list.

**Training & Updating the Model**

- Add labeled images and update `data_roboflow.yaml`.
- Train with `train_roboflow.py` (see file for exact usage).
- Trained weights appear in `runs/train/<name>/weights/best.pt`.

**Practical Tips**

- Use steady lighting and clear camera views for best results.
- Add examples of confusing cases to the training data to reduce mistakes.
- For embedded devices, use a smaller model or run inference on a server.

**Files You Care About**

- `smart_dustbin_smooth.py` â€” Main runtime (inference + behavior).
- `webcam_fresh.py` â€” Simple demo to test detection.
- `train_roboflow.py` & `data_roboflow.yaml` â€” Training pipeline configuration.
- `CLEANUP_SUMMARY.md` â€” Project cleanup notes.
- `requirements.txt` â€” Python dependencies.

**Where to Change Behavior**

- Edit thresholds and smoothing in `smart_dustbin_smooth.py`.
- Change class-to-action mapping in the main script to customize bin behavior.

## ğŸ“ Final Clean Structure:

```
d:\minor project\try 1\
â”‚
â”œâ”€â”€ ğŸ“± Applications
â”‚   â”œâ”€â”€ smart_dustbin_smooth.py      â­ Main (recommended)
â”‚   â”œâ”€â”€ smart_dustbin_esp32.py       Alternative
â”‚   â””â”€â”€ webcam_fresh.py              Demo
â”‚
â”œâ”€â”€ ğŸ“ Training
â”‚   â”œâ”€â”€ train_roboflow.py
â”‚   â””â”€â”€ data_roboflow.yaml
â”‚
â”œâ”€â”€ ğŸ“š Documentation
â”‚   â”œâ”€â”€ README_NEW.md                â­ Updated README
â”‚   â”œâ”€â”€ SMOOTH_MODE_GUIDE.md
â”‚   â”œâ”€â”€ ESP32_SETUP_GUIDE.md
â”‚   â”œâ”€â”€ FRESH_TRAINING_STATUS.md
â”‚   â””â”€â”€ CLEANUP_PLAN.md
â”‚
â”œâ”€â”€ âš™ï¸ Configuration
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ .gitignore
â”‚   â””â”€â”€ cleanup.ps1
â”‚
â”œâ”€â”€ ğŸ¤– Model & Results
â”‚   â””â”€â”€ runs/
â”‚       â””â”€â”€ train/
â”‚           â””â”€â”€ roboflow_fresh/
â”‚               â””â”€â”€ weights/
â”‚                   â”œâ”€â”€ best.pt      â­ Your model
â”‚                   â””â”€â”€ last.pt
â”‚
â””â”€â”€ ğŸ Environment
    â””â”€â”€ .venv/                        Python packages
```

---
